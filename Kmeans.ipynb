{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../project/processed_data_with_timeindex.csv',index_col = [0])\n",
    "data.index = pd.to_datetime(data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_data.csv',index_col = [0])\n",
    "data.index = pd.to_datetime(data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering by daily load pattern\n",
    "# compute average daily pattern\n",
    "daily_pattern = pd.DataFrame(columns = data.columns)\n",
    "for i in data.columns:\n",
    "    daily_pattern[i] = np.nanmean(np.array(data[i][:(data.shape[0] - data.shape[0]%(60*24))]).reshape(-1,24*60),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering by daily load pattern\n",
    "# compute average daily pattern\n",
    "daily_pattern = pd.DataFrame(columns = data.columns)\n",
    "for i in data.columns:\n",
    "    daily_pattern[i] = np.nanmean(np.array(data[i][:(data.shape[0] - data.shape[0]%(60*24))]).reshape(-1,24*60),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pattern = daily_pattern.loc[:,daily_pattern.columns[daily_pattern.std(0)!=0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "# plot elbow plot\n",
    "def elbow_plot(X,n_clusters = np.arange(1,40,2)):\n",
    "    distortions = []\n",
    "    for n in n_clusters:\n",
    "        kmmodel = KMeans(n)\n",
    "        kmmodel.fit(X.T)\n",
    "        distortions.append(sum(np.min(cdist(X.T, kmmodel.cluster_centers_, 'euclidean'), axis=1)) / X.T.shape[0])\n",
    "    plt.plot(n_clusters, distortions, 'bx-')\n",
    "    plt.xticks(n_clusters)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('The Elbow Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def labeled_plot(X,k=31,xnum=4,ynum=8,silent = True):\n",
    "    '''\n",
    "    k should <= xnum*ynum\n",
    "    '''\n",
    "    X = X.reset_index(drop = True)\n",
    "    kmmodel = KMeans(k)\n",
    "    kmmodel.fit(X.T)\n",
    "    clusters_dict = {label:0 for label in set(kmmodel.labels_)}\n",
    "    for i in kmmodel.labels_:\n",
    "        clusters_dict[i] += 1\n",
    "    count = pd.DataFrame(clusters_dict,index = ['count']).T.sort_values(by = 'count',ascending = False)\n",
    "    clusters_dict = {label:0 for label in count.index}\n",
    "    for label in count.index:\n",
    "        clusters_dict[label] = X.iloc[:,kmmodel.labels_ == label]\n",
    "    if not silent:\n",
    "        fig = plt.figure(figsize=(20,8))\n",
    "        for k,label in enumerate(count.index):\n",
    "            fig.add_subplot(xnum,ynum,k+1).plot(clusters_dict[label]+0.5,alpha = 0.06)\n",
    "#             plt.subplot(xnum,ynum,k+1).plot(clusters_dict[label].mean(1),'r')\n",
    "            plt.plot(clusters_dict[label].mean(1)+0.5,'r')\n",
    "    return clusters_dict\n",
    "\n",
    "def save_dict(cluster_dicts, file_name):\n",
    "    with open(file_name,'wb+') as f:\n",
    "        pickle.dump(clusters_dict,f)\n",
    "        \n",
    "def normalized(load):\n",
    "    peak = load.max(axis=1)[:, None]\n",
    "    trough = load.min(axis=1)[:, None]\n",
    "    diff = peak - trough\n",
    "    diff[diff == 0.] = 1.\n",
    "    normalized = (load - trough) / diff\n",
    "    return normalized\n",
    "\n",
    "def resample_normalization(data,granularity = '1min'):\n",
    "    data.index = pd.date_range('2016-01-01-00:00:00','2016-01-01-23:59:59',freq = 'min')\n",
    "    data = data.resample(granularity,label = 'left').mean()\n",
    "    data = (data - data.min(0))/(data.max(0) - data.min(0)) - 0.5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def labeled_plot(X,plot_data,k=31,xnum=4,ynum=8,silent = True):\n",
    "    '''\n",
    "    k should <= xnum*ynum\n",
    "    '''\n",
    "    X = X.reset_index(drop = True)\n",
    "    kmmodel = KMeans(k)\n",
    "    kmmodel.fit(X.T)\n",
    "    clusters_dict = {label:0 for label in set(kmmodel.labels_)}\n",
    "    for i in kmmodel.labels_:\n",
    "        clusters_dict[i] += 1\n",
    "    count = pd.DataFrame(clusters_dict,index = ['count']).T.sort_values(by = 'count',ascending = False)\n",
    "    clusters_dict = {label:0 for label in count.index}\n",
    "    for label in count.index:\n",
    "        clusters_dict[label] = plot_data.iloc[:,kmmodel.labels_ == label]\n",
    "    if not silent:\n",
    "        fig = plt.figure(figsize=(20,8))\n",
    "        for k,label in enumerate(count.index):\n",
    "            fig.add_subplot(xnum,ynum,k+1).plot(clusters_dict[label]+0.5,alpha = 0.3)\n",
    "#             plt.subplot(xnum,ynum,k+1).plot(clusters_dict[label].mean(1),'r')\n",
    "            plt.plot(clusters_dict[label].mean(1)+0.5,'r')\n",
    "    return clusters_dict\n",
    "\n",
    "def save_dict(cluster_dicts, file_name):\n",
    "    with open(file_name,'wb+') as f:\n",
    "        pickle.dump(clusters_dict,f)\n",
    "        \n",
    "def normalized(load):\n",
    "    peak = load.max(axis=0)\n",
    "    trough = load.min(axis=0)\n",
    "    diff = peak - trough\n",
    "    diff[diff == 0.] = 1.\n",
    "    normalized = (load - trough) / diff\n",
    "    return normalized\n",
    "\n",
    "def resample_normalization(data,granularity = '1min'):\n",
    "    data.index = pd.date_range('2016-01-01-00:00:00','2016-01-01-23:59:59',freq = 'min')\n",
    "    data = data.resample(granularity,label = 'left').mean()\n",
    "    data = normalized(data) - 0.5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_plot(resample_normalization(daily_pattern,'1min'),n_clusters = np.arange(1,40,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resample_normalization(daily_pattern,'1min').iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_plot(resample_normalization(daily_pattern,'1min'),n_clusters = np.arange(1,40,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'1min'),5,2,3,silent = False)\n",
    "for val in clusters_dict.values():\n",
    "    print(val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# granularity 1min 31 clusters\n",
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'1min'),6,2,3,silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# granularity 1min 31 clusters\n",
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'1min'),resample_normalization(daily_pattern,'1min'), 7, 2, 4, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'1min'),12,3,4,silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_plot(resample_normalization(daily_pattern,'10min'),n_clusters = np.arange(1,40,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'10min'),31,4,8,silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'10min'),12,3,4,silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_plot(resample_normalization(daily_pattern,'30min'),n_clusters = np.arange(1,40,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'30min'),5,2,3,silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = labeled_plot(resample_normalization(daily_pattern,'30min'),12,3,4,silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('kmeans_granuity_1min.pkg','wb+') as f:\n",
    "    pickle.dump(clusters_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans with pca\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "latent = PCA(n_components = 16).fit_transform(resample_normalization(daily_pattern,'1min').T)\n",
    "latent = pd.DataFrame(latent).T\n",
    "cluster_dict = labeled_plot(latent,plot_data=resample_normalization(daily_pattern,'1min'),k=7,xnum=2,ynum=4,silent = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pattern.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_normalization(daily_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [0.00, 0.05, 0.10, 0.25, 0.35, 0.60, 0.73, 0.80]\n",
    "kmeans = [0.614, 0.563, 0.433, 0.331, 0.094, 0.00, 0.00, 0.00]\n",
    "ae = [1, 1, 1, 0.999, 0.999, 1, 0.985, 0]\n",
    "for i in range(1,len(sigma)+1):\n",
    "    fig,ax=plt.subplots()\n",
    "    plt.rcParams['figure.figsize'] =(13.02,7.84)\n",
    "    plt.plot(list(range(len(sigma[:i]))),np.array(ae[:i])*100,'x-',c='#029386',linewidth=3,markeredgewidth=5,markersize=10,label = 'Auto Encoder K-means')\n",
    "    plt.plot(list(range(len(sigma[:i]))),np.array(kmeans[:i])*100,'x-',c='#fc5a50',linewidth=3,markeredgewidth=5,markersize=10,label = 'Naive K-means')\n",
    "    \n",
    "    plt.legend(fontsize=15,loc='lower left')\n",
    "    plt.xticks(list(range(len(sigma))),sigma)\n",
    "    plt.yticks([p for p in range(0, 101, 20)],[f'{p}%' for p in range(0, 101, 20)])\n",
    "    plt.xlabel('$\\sigma$',fontsize=20)\n",
    "#     plt.ylabel('Success Rate',fontsize=20)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig('graphics\\\\'+str(i)+'.png',format='png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "840/317"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
