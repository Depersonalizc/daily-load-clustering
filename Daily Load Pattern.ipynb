{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from torch import nn, functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IN_DAY = 1440\n",
    "CUTOFF = 172800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = np.array(df.iloc[:, 1:])[:CUTOFF].T  # 346 residents, 172800 min\n",
    "daily = daily.reshape((daily.shape[0], -1, MIN_IN_DAY))  # 346 residents, 120 days, 1440 minutes\n",
    "daily = np.nanmean(daily, axis=1)  # 346 residents, 1440 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, daily.shape[0]-1))\n",
    "def plot_daily_load(resident=31):\n",
    "    plt.plot(daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(load):\n",
    "    peak = load.max(axis=1)[:, None]\n",
    "    trough = load.min(axis=1)[:, None]\n",
    "    diff = peak - trough\n",
    "    diff[diff == 0.] = 1.\n",
    "    normalized = (load - trough) / diff\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_daily = normalized(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, normalized_daily.shape[0]-1))\n",
    "def plot_normalized_daily(resident=217):\n",
    "    plt.plot(normalized_daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class DS(Dataset):\n",
    "    def __init__(self, data, sep, train=True):\n",
    "        super().__init__()\n",
    "        if train:\n",
    "            self.data = torch.Tensor(data[:sep]).cuda()\n",
    "        else:\n",
    "            self.data = torch.Tensor(data[sep:]).cuda()\n",
    "        self.data.unsqueeze_(1)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with MLP\n",
    "class AE_MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        encoder = []\n",
    "        decoder = []\n",
    "        act = cfg['activation']\n",
    "        \n",
    "        # encoder\n",
    "        for i in range(len(cfg['encoder']) - 1):\n",
    "            cin, cout = cfg['encoder'][i], cfg['encoder'][i+1]\n",
    "            encoder.append(nn.Linear(cin, cout))\n",
    "            encoder.append(act)\n",
    "\n",
    "        # decoder\n",
    "        for i in range(len(cfg['decoder']) - 1):\n",
    "            cin, cout = cfg['decoder'][i], cfg['decoder'][i+1]\n",
    "            decoder.append(nn.Linear(cin, cout))\n",
    "            decoder.append(act)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'activation': nn.ReLU(),\n",
    "    'encoder': [1440, 256, 64, 4],\n",
    "    'decoder': [4, 64, 256, 1440]\n",
    "}\n",
    "model = AE_MLP(cfg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(conv_ae.state_dict(), 'models/AE_CNN_d=16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "# Autoencoder using CNN\n",
    "class AE_CNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        act = cfg['activation']\n",
    "        \n",
    "        # encoder\n",
    "        enc = [\n",
    "            # 1440 -> 288\n",
    "            nn.Conv1d(1, 16, 5, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=5),\n",
    "            act,\n",
    "            # 288 -> 72\n",
    "            nn.Conv1d(16, 32, 4, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            act,\n",
    "            # 72 -> 24\n",
    "            nn.Conv1d(32, 1, 3, padding=1),\n",
    "            nn.MaxPool1d(kernel_size=3),\n",
    "            act,\n",
    "            # 24 -> D (fully connected)\n",
    "            nn.Conv1d(1, 16, 24),\n",
    "            act,\n",
    "            # now we have our latent vector with shape (B, 16, 1)\n",
    "        ]\n",
    "\n",
    "        # decoder\n",
    "        dec = [\n",
    "            # D -> 24\n",
    "            nn.Conv1d(1, 32, 3, padding=1),\n",
    "            nn.Upsample(72),\n",
    "            act,\n",
    "            # 32 -> 96\n",
    "            nn.Conv1d(32, 16, 4, padding=2),\n",
    "            nn.Upsample(288),\n",
    "            act,\n",
    "            # 96 -> 288\n",
    "            nn.Conv1d(16, 1, 5, padding=2),\n",
    "            nn.Upsample(1440),\n",
    "            nn.Tanh(),\n",
    "        ]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x).permute(0, 2, 1)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'activation': nn.ReLU()\n",
    "}\n",
    "\n",
    "conv_ae = AE_CNN(cfg).cuda()\n",
    "conv_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-reporter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "# At each epoch, randomly shuffle the daily loads, then feed in the network sequentially.\n",
    "ntraindata = 250\n",
    "epoch = 1000\n",
    "lr = 1e-4 * 2\n",
    "optim = torch.optim.Adam(conv_ae.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "bsz = 125\n",
    "train_dataset = DS(normalized_daily, ntraindata, train=True)\n",
    "test_dataset = DS(normalized_daily, ntraindata, train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_data = iter(test_loader).next()\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_epoch(train_loss, val_loss, val_data, recon_data, rows=4, cols=4, epoch=-1, saveat=None):\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    ax0 = fig.add_subplot(gs[0])\n",
    "    ax0.set_xlabel('Epochs', fontsize=11, weight='semibold')\n",
    "    ax0.set_ylabel('MSE', fontsize=11, weight='semibold')\n",
    "    ax0.plot(train_loss, color='#fc5a50', label='Train', alpha=0.9)\n",
    "    ax0.plot(val_loss, color='#029386', label='Validation', alpha=0.9)\n",
    "    ax0.spines['right'].set_visible(False)\n",
    "    ax0.spines['top'].set_visible(False)\n",
    "    ax0.set_ylim([0., 0.1])\n",
    "    ax0.legend(prop={'size': 11,})\n",
    "    grid = gridspec.GridSpecFromSubplotSpec(rows, cols, subplot_spec=gs[1])\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = fig.add_subplot(grid[i, j])\n",
    "            idx = i * rows + j\n",
    "            ax.plot(test_data[idx][0].detach().cpu(), color='#2b7ce0', alpha=0.6)\n",
    "            ax.plot(recon_data[idx][0].detach().cpu(), color='#e02b5b', alpha=0.9) # # #e03d2b\n",
    "            ax.set_ylim([0., 1.])\n",
    "            ax.axis('off')\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "    if saveat is not None:\n",
    "        plt.savefig(f'{saveat}/{epoch}.png', format='png')\n",
    "    plt.show()\n",
    "\n",
    "for e in range(epoch):\n",
    "    for ibatch, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        latent, recon = conv_ae(batch)\n",
    "        loss = loss_fn(recon, batch)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        train_loss.append(loss.item())\n",
    "#         axs[0].plot(train_loss)\n",
    "#         axs[0].title.set_text('Training Loss')\n",
    "        # evaluate network\n",
    "        with torch.no_grad():\n",
    "            latent, recon = conv_ae(test_data)\n",
    "            loss = loss_fn(recon, test_data)\n",
    "            test_loss.append(loss.item())\n",
    "            vis_epoch(train_loss, test_loss, test_data, recon, \n",
    "                      rows=4, cols=4, epoch=e, saveat='/home/jamie/Desktop/graphics')\n",
    "#             axs[1].plot(test_loss)\n",
    "#             axs[1].title.set_text('Validation Loss')\n",
    "            \n",
    "#             vis = np.random.randint(0, test_data.shape[0])\n",
    "#             axs[2].plot(test_data[vis][0].detach().cpu())\n",
    "#             axs[2].plot(recon[vis][0].detach().cpu())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae.load_state_dict(torch.load('models/AE_CNN_d=16.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.data\n",
    "data_c = data.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, pred = conv_ae(data)\n",
    "latent = latent.detach().cpu().numpy()[:, 0]\n",
    "pred = pred.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, data.shape[0]-1))\n",
    "def plot_normalized_daily(resident=217):\n",
    "    plt.plot(data_c[resident])\n",
    "    plt.plot(pred[resident])\n",
    "    plt.show()\n",
    "    print(latent[resident])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=clusters, random_state=2000).fit(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(latent_vec: np.array, model):\n",
    "    latent_tensor = torch.Tensor(latent_vec[None,:,None]).cuda()\n",
    "    with torch.no_grad():\n",
    "        decoded = model.decoder(latent_tensor.permute(0, 2, 1))\n",
    "    return decoded.cpu().numpy()[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(Cluster=(0, clusters-1))\n",
    "def plot_cluster(Cluster):\n",
    "    resd = (kmeans.labels_==Cluster)\n",
    "    load = data_c[resd]\n",
    "    mean = load.mean(axis=0)\n",
    "    centroid = kmeans.cluster_centers_[Cluster]\n",
    "    decoded_mean = decode(centroid, conv_ae)\n",
    "    print(f'{load.shape[0]} residents')\n",
    "    plt.plot(load.T, alpha=0.03)\n",
    "    plt.plot(mean, c='red')\n",
    "    plt.plot(decoded_mean, c='green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-ceremony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-railway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
