{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from torch import nn, functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IN_DAY = 1440\n",
    "CUTOFF = 172800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = np.array(df.iloc[:, 1:])[:CUTOFF].T  # 346 residents, 172800 min\n",
    "daily = daily.reshape((daily.shape[0], -1, MIN_IN_DAY))  # 346 residents, 120 days, 1440 minutes\n",
    "daily = np.nanmean(daily, axis=1)  # 346 residents, 1440 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, daily.shape[0]-1))\n",
    "def plot_daily_load(resident=31):\n",
    "    plt.plot(daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(load):\n",
    "    peak = load.max(axis=1)[:, None]\n",
    "    trough = load.min(axis=1)[:, None]\n",
    "    diff = peak - trough\n",
    "    diff[diff == 0.] = 1.\n",
    "    normalized = (load - trough) / diff\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_daily = normalized(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, normalized_daily.shape[0]-1))\n",
    "def plot_normalized_daily(resident=217):\n",
    "    plt.plot(normalized_daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Training\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class DS(Dataset):\n",
    "    def __init__(self, data, sep, train=True):\n",
    "        super().__init__()\n",
    "        if train:\n",
    "            self.data = torch.Tensor(data[:sep]).cuda()\n",
    "        else:\n",
    "            self.data = torch.Tensor(data[sep:]).cuda()\n",
    "        self.data.unsqueeze_(1)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        encoder = []\n",
    "        decoder = []\n",
    "        act = cfg['activation']\n",
    "        \n",
    "        # encoder\n",
    "        for i in range(len(cfg['encoder']) - 1):\n",
    "            cin, cout = cfg['encoder'][i], cfg['encoder'][i+1]\n",
    "            encoder.append(nn.Linear(cin, cout))\n",
    "            encoder.append(act)\n",
    "\n",
    "        # decoder\n",
    "        for i in range(len(cfg['decoder']) - 1):\n",
    "            cin, cout = cfg['decoder'][i], cfg['decoder'][i+1]\n",
    "            decoder.append(nn.Linear(cin, cout))\n",
    "            decoder.append(act)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'activation': nn.ReLU(),\n",
    "    'encoder': [1440, 256, 64, 4],\n",
    "    'decoder': [4, 64, 256, 1440]\n",
    "}\n",
    "model = AE_MLP(cfg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-methodology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/AE_CNN_sigmoid_d=16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "class AE_CNN(nn.Module):\n",
    "    def __init__(self, cfg, load_dict=None):\n",
    "        super().__init__()\n",
    "        act = cfg['activation']\n",
    "        d = cfg['latent_dim']\n",
    "        \n",
    "        # encoder\n",
    "        enc = [\n",
    "            # 1440 -> 288\n",
    "            nn.Conv1d(1, 16, 5, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=5),\n",
    "            act,\n",
    "            \n",
    "            # 288 -> 72\n",
    "            nn.Conv1d(16, 32, 4, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            act,\n",
    "            \n",
    "            # 32*72\n",
    "            nn.Flatten(),\n",
    "            # 32*72 -> d (fully connected)\n",
    "            nn.Linear(32*72, d),\n",
    "#             nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        # decoder\n",
    "        dec = [\n",
    "            # d -> 32*72 (fully connected)\n",
    "            nn.Linear(d, 32*72),\n",
    "#             nn.ReLU(),\n",
    "            # 72\n",
    "            View((32, 72)),\n",
    "\n",
    "            # 32 -> 96\n",
    "            nn.Conv1d(32, 16, 4, padding=2),\n",
    "            nn.Upsample(288),\n",
    "            act,\n",
    "            \n",
    "            # 96 -> 288\n",
    "            nn.Conv1d(16, 1, 5, padding=2),\n",
    "            nn.Upsample(1440),\n",
    "#             nn.Tanh()\n",
    "            nn.Sigmoid(),\n",
    "        ]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "        \n",
    "        if load_dict is not None:\n",
    "            self.load_state_dict(torch.load(load_dict))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'latent_dim': 8,\n",
    "    'activation': nn.ReLU(),\n",
    "}\n",
    "\n",
    "model_dict = 'models/AE_CNN_sigmoid_d=8.pt'\n",
    "# model_dict = None\n",
    "model = AE_CNN(cfg, model_dict)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(test_data).shape\n",
    "l, r = model(test_data)\n",
    "l.shape, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-lingerie",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "# At each epoch, randomly shuffle the daily loads, then feed in the network sequentially.\n",
    "ntraindata = 250\n",
    "epoch = 1000\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "bsz = 125\n",
    "train_dataset = DS(normalized_daily, ntraindata, train=True)\n",
    "test_dataset = DS(normalized_daily, ntraindata, train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_data = iter(test_loader).next()\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_epoch(train_loss, val_loss, val_data, recon_data, rows=4, cols=4, epoch=-1, saveat=None):\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    ax0 = fig.add_subplot(gs[0])\n",
    "    ax0.set_xlabel('Epochs', fontsize=11, weight='semibold')\n",
    "    ax0.set_ylabel('MSE', fontsize=11, weight='semibold')\n",
    "    ax0.plot(train_loss, color='#fc5a50', label='Train', alpha=0.9)\n",
    "    ax0.plot(val_loss, color='#029386', label='Validation', alpha=0.9)\n",
    "    ax0.spines['right'].set_visible(False)\n",
    "    ax0.spines['top'].set_visible(False)\n",
    "    ax0.set_ylim([0., 0.1])\n",
    "    ax0.legend(prop={'size': 11,})\n",
    "    grid = gridspec.GridSpecFromSubplotSpec(rows, cols, subplot_spec=gs[1])\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = fig.add_subplot(grid[i, j])\n",
    "            idx = i * rows + j\n",
    "            ax.plot(test_data[idx][0].detach().cpu(), color='#2b7ce0', alpha=0.6)\n",
    "            ax.plot(recon_data[idx][0].detach().cpu(), color='#e02b5b', alpha=0.9) # # #e03d2b\n",
    "            ax.set_ylim([0., 1.])\n",
    "            ax.axis('off')\n",
    "    if saveat is not None:\n",
    "        plt.savefig(f'{saveat}/{epoch}.png', format='png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Training loops\n",
    "for e in range(epoch):\n",
    "    for ibatch, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        latent, recon = model(batch)\n",
    "        loss = loss_fn(recon, batch)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        train_loss.append(loss.item())\n",
    "        # evaluate network\n",
    "        with torch.no_grad():\n",
    "            latent, recon = model(test_data)\n",
    "            loss = loss_fn(recon, test_data)\n",
    "            test_loss.append(loss.item())\n",
    "            vis_epoch(train_loss, test_loss, test_data, recon, \n",
    "                      rows=4, cols=4, epoch=e, saveat='/home/jamie/Desktop/graphics')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# WILLLLD EXPERIMENTS!\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DS(normalized_daily, sep=0, train=False).data\n",
    "data_c = data.detach().cpu().numpy()[:, 0]\n",
    "\n",
    "latent, pred = model(data)\n",
    "latent = latent.detach().cpu().numpy()\n",
    "pred = pred.detach().cpu().numpy()[:, 0]\n",
    "latent.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, data.shape[0]-1))\n",
    "def plot_reconstruction(resident=data.shape[0]//2):\n",
    "    plt.plot(data_c[resident])\n",
    "    plt.plot(pred[resident])\n",
    "    plt.show()\n",
    "    print(np.around(latent[resident], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=clusters, random_state=2000).fit(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(latent_vec: np.array, model) -> np.array:\n",
    "    latent_tensor = torch.Tensor(latent_vec[None,:,None]).cuda()\n",
    "    with torch.no_grad():\n",
    "        decoded = model.decoder(latent_tensor.permute(0, 2, 1))\n",
    "    return decoded.cpu().numpy()[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(Cluster=(0, clusters-1))\n",
    "def plot_cluster(Cluster):\n",
    "    import math\n",
    "    resd = (kmeans.labels_==Cluster)\n",
    "    load = data_c[resd]\n",
    "    mean = load.mean(axis=0)\n",
    "    centroid = kmeans.cluster_centers_[Cluster]\n",
    "    decoded_mean = decode(centroid, model)\n",
    "    print(f'{load.shape[0]} residents')\n",
    "    alpha = 1.0 / math.sqrt(load.shape[0]) / 2.\n",
    "    plt.plot(load.T, alpha=alpha)\n",
    "    plt.plot(mean, c='red')\n",
    "    plt.plot(decoded_mean, c='green')\n",
    "    plt.show()\n",
    "    print('Latent centroid:')\n",
    "    print(np.around(centroid, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(8)\n",
    "\n",
    "@widgets.interact(di=(-5.00, 5.00, 0.001))\n",
    "def plot_decoded(di:float):\n",
    "    x[4] = di\n",
    "    decoded_mean = decode(x, model)\n",
    "#     print(f'{load.shape[0]} residents')\n",
    "#     alpha = 1.0 / math.sqrt(load.shape[0]) / 2.\n",
    "#     plt.plot(load.T, alpha=alpha)\n",
    "#     plt.plot(mean, c='red')\n",
    "    plt.plot(decoded_mean, c='green')\n",
    "    plt.show()\n",
    "    print(np.around(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-split",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
