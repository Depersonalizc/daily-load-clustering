{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from torch import nn, functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IN_DAY = 1440\n",
    "CUTOFF = 172800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = np.array(df.iloc[:, 1:])[:CUTOFF].T  # 346 residents, 172800 min\n",
    "daily = daily.reshape((daily.shape[0], -1, MIN_IN_DAY))  # 346 residents, 120 days, 1440 minutes\n",
    "daily = np.nanmean(daily, axis=1)  # 346 residents, 1440 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, daily.shape[0]-1))\n",
    "def plot_daily_load(resident=31):\n",
    "    plt.plot(daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(load):\n",
    "    peak = load.max(axis=1)[:, None]\n",
    "    trough = load.min(axis=1)[:, None]\n",
    "    diff = peak - trough\n",
    "    diff[diff == 0.] = 1.\n",
    "    normalized = (load - trough) / diff\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_daily = normalized(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, normalized_daily.shape[0]-1))\n",
    "def plot_normalized_daily(resident=217):\n",
    "    plt.plot(normalized_daily[resident])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class DS(Dataset):\n",
    "    def __init__(self, data, sep, train=True):\n",
    "        super().__init__()\n",
    "        if train:\n",
    "            self.data = torch.Tensor(data[:sep]).cuda()\n",
    "        else:\n",
    "            self.data = torch.Tensor(data[sep:]).cuda()\n",
    "        self.data.unsqueeze_(1)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with MLP\n",
    "class AE_MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        encoder = []\n",
    "        decoder = []\n",
    "        act = cfg['activation']\n",
    "        \n",
    "        # encoder\n",
    "        for i in range(len(cfg['encoder']) - 1):\n",
    "            cin, cout = cfg['encoder'][i], cfg['encoder'][i+1]\n",
    "            encoder.append(nn.Linear(cin, cout))\n",
    "            encoder.append(act)\n",
    "\n",
    "        # decoder\n",
    "        for i in range(len(cfg['decoder']) - 1):\n",
    "            cin, cout = cfg['decoder'][i], cfg['decoder'][i+1]\n",
    "            decoder.append(nn.Linear(cin, cout))\n",
    "            decoder.append(act)\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'activation': nn.ReLU(),\n",
    "    'encoder': [1440, 256, 64, 4],\n",
    "    'decoder': [4, 64, 256, 1440]\n",
    "}\n",
    "model = AE_MLP(cfg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "# Autoencoder using CNN\n",
    "    \n",
    "class AE_CNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        act = cfg['activation']\n",
    "        \n",
    "        # encoder\n",
    "        enc = [\n",
    "            # 1440 -> 288\n",
    "            nn.Conv1d(1, 16, 5, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=5),\n",
    "            act,\n",
    "            # 288 -> 72\n",
    "            nn.Conv1d(16, 32, 4, padding=2),\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            act,\n",
    "            # 72 -> 24\n",
    "            nn.Conv1d(32, 1, 3, padding=1),\n",
    "            nn.MaxPool1d(kernel_size=3),\n",
    "            act,\n",
    "            # 24 -> 8 (fully connected)\n",
    "            nn.Conv1d(1, 16, 24),\n",
    "            act,\n",
    "            # now we have our latent vector with shape (B, 16, 1)\n",
    "        ]\n",
    "\n",
    "        # decoder\n",
    "        dec = [\n",
    "            # 8 -> 24\n",
    "            nn.Conv1d(1, 32, 3, padding=1),\n",
    "            nn.Upsample(72),\n",
    "            act,\n",
    "            # 32 -> 96\n",
    "            nn.Conv1d(32, 16, 4, padding=2),\n",
    "            nn.Upsample(288),\n",
    "            act,\n",
    "            # 96 -> 288\n",
    "            nn.Conv1d(16, 1, 5, padding=2),\n",
    "            nn.Upsample(1440),\n",
    "            nn.Tanh(),\n",
    "        ]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x).permute(0, 2, 1)\n",
    "        recon = self.decoder(latent)\n",
    "        return latent, recon\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'activation': nn.ReLU()\n",
    "}\n",
    "\n",
    "conv_ae = AE_CNN(cfg).cuda()\n",
    "conv_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-analyst",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "# At epoch, randomly shuffle the daily loads, then feed in the network sequentially.\n",
    "ntraindata = 250\n",
    "epoch = 100000\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(conv_ae.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "bsz = 125\n",
    "train_dataset = DS(normalized_daily, 10000, train=True)\n",
    "test_dataset = DS(normalized_daily, ntraindata, train=False)\n",
    "# train_dataset = DS(daily, ntraindata, train=True)\n",
    "# test_dataset = DS(daily, ntraindata, train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epoch):\n",
    "    for ibatch, batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        latent, recon = conv_ae(batch)\n",
    "        loss = loss_fn(recon, batch)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "        train_loss.append(loss.item())\n",
    "        axs[0].plot(train_loss)\n",
    "        # evaluate network\n",
    "        with torch.no_grad():\n",
    "            test_data = iter(test_loader).next()\n",
    "            _, recon = conv_ae(test_data)\n",
    "            loss = loss_fn(recon, test_data)\n",
    "            test_loss.append(loss.item())\n",
    "            axs[1].plot(test_loss)\n",
    "            vis = np.random.randint(0, test_data.shape[0])\n",
    "            axs[2].plot(test_data[vis][0].detach().cpu())\n",
    "            axs[2].plot(recon[vis][0].detach().cpu())\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ae.load_state_dict(torch.load('models/AE_CNN_d=16.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.data\n",
    "data_c = data.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, pred = conv_ae(data)\n",
    "latent = latent.detach().cpu().numpy()[:, 0]\n",
    "pred = pred.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(resident=(0, data.shape[0]-1))\n",
    "def plot_normalized_daily(resident=217):\n",
    "    plt.plot(data_c[resident])\n",
    "    plt.plot(pred[resident])\n",
    "    plt.show()\n",
    "    print(latent[resident])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=clusters, random_state=2000).fit(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(latent_vec: np.array, model):\n",
    "    latent_tensor = torch.Tensor(latent_vec[None,:,None]).cuda()\n",
    "    with torch.no_grad():\n",
    "        decoded = model.decoder(latent_tensor.permute(0, 2, 1))\n",
    "    return decoded.cpu().numpy()[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(Cluster=(0, clusters-1))\n",
    "def plot_cluster(Cluster):\n",
    "    resd = (kmeans.labels_==Cluster)\n",
    "    load = data_c[resd]\n",
    "    mean = load.mean(axis=0)\n",
    "    centroid = kmeans.cluster_centers_[Cluster]\n",
    "    decoded_mean = decode(centroid, conv_ae)\n",
    "    print(f'{load.shape[0]} residents')\n",
    "    plt.plot(load.T, alpha=0.03)\n",
    "    plt.plot(mean, c='red')\n",
    "    plt.plot(decoded_mean, c='green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-nightmare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-probability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
